{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n",
      "\n",
      "\n",
      "载入程序包：'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "载入程序包：'lubridate'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "载入需要的程序包：future\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 加载所需的库\n",
    "# -----------------------------\n",
    "library(blackmarbler)    # 用于 NASA Black Marble 数据提取\n",
    "library(sf)              # 用于空间数据处理\n",
    "library(dplyr)           # 用于数据操作\n",
    "library(lubridate)       # 用于日期处理\n",
    "library(purrr)           # 用于映射和结果合并\n",
    "library(future.apply)    # 用于并行处理\n",
    "\n",
    "# -----------------------------\n",
    "# 调整 future 包允许传递的全局变量大小（这里设置为 2GB）\n",
    "# -----------------------------\n",
    "options(future.globals.maxSize = 1024^3)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 读取区域边界文件并转换到 WGS84 投影\n",
    "# -----------------------------\n",
    "local_area_sf <- st_read(\"local-area-boundary.geojson\", quiet = TRUE) %>%\n",
    "  st_transform(4326)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. 设置 NASA 的 Bearer Token（请替换为你自己的 token）\n",
    "# -----------------------------\n",
    "bearer <- \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImplcnJvbGRodWFuZyIsImV4cCI6MTc0NzYyOTM3MiwiaWF0IjoxNzQyNDQ1MzcyLCJpc3MiOiJodHRwczovL3Vycy5lYXJ0aGRhdGEubmFzYS5nb3YiLCJpZGVudGl0eV9wcm92aWRlciI6ImVkbF9vcHMiLCJhY3IiOiJlZGwiLCJhc3N1cmFuY2VfbGV2ZWwiOjN9.DepsZDUC1Frvrf3qaR379e3am9nIZh8uC1yT_RoqbIlilX730CZ-Fa3K9KmiS2ZPSknV98aPAao5sPIBGiiyyLyDL8xqsL1Yk2-qFUnQEJf0hqLPtT78zzkvOX75UuM79ou_mGkq2-eygefFXXjdKEDP8PvQZbdeGxM2d4F83LYSKpcabtgU8MlkgEszhsrDzrotlxKKwuXQVfe1ojk6fIFPKhJV7Jj2qnsp9QCpcpXKy6osskDue5eXWAkzbbWTYLhjKuz_PYeeAUvlj-rvss8hnPFHbxNYFAM-dndAIphbwB-rwGsXhT4aE0wUchbCmBzNFFSfyKHIcrcoHP-kag\"\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 定义函数：按天提取数据（带有重试逻辑）\n",
    "# -----------------------------\n",
    "bm_extract_day <- function(date_char, roi_sf, bearer, wait_seconds = 10) {\n",
    "  # 根据日期创建输出文件夹（按年份组织）\n",
    "  year <- format(as.Date(date_char), \"%Y\")\n",
    "  out_dir <- file.path(\"bm_files_daily\", year)\n",
    "  if (!dir.exists(out_dir)) {\n",
    "    dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "  }\n",
    "  \n",
    "  # 定义输出文件名（例如 \"vnp46a2_2023-01-15.Rds\"）\n",
    "  out_file <- file.path(out_dir, paste0(\"vnp46a2_\", date_char, \".Rds\"))\n",
    "  \n",
    "  repeat {\n",
    "    result <- tryCatch({\n",
    "      bm_extract(\n",
    "        roi_sf = roi_sf,\n",
    "        product_id = \"VNP46A2\",       # 每日夜光数据产品\n",
    "        date = date_char,             # 单个日期，格式 \"YYYY-MM-DD\"\n",
    "        bearer = bearer,\n",
    "        aggregation_fun = \"mean\",\n",
    "        variable = \"NearNadir_Composite_Snow_Free\",  # 根据需要调整变量\n",
    "        add_n_pixels = TRUE,\n",
    "        output_location_type = \"file\",\n",
    "        file_dir = out_dir,\n",
    "        file_prefix = \"vnp46a2_\",\n",
    "        file_skip_if_exists = TRUE,\n",
    "        file_return_null = TRUE\n",
    "      )\n",
    "    }, error = function(e) {\n",
    "      # 如果遇到 HTTP 401 Unauthorized 错误，等待指定秒数后重试\n",
    "      if (grepl(\"HTTP 401 Unauthorized\", e$message)) {\n",
    "        message(sprintf(\"日期 %s 出现 401 Unauthorized 错误，等待 %d 秒后重试...\", \n",
    "                        date_char, wait_seconds))\n",
    "        Sys.sleep(wait_seconds)\n",
    "        return(e)\n",
    "      } else {\n",
    "        stop(e)\n",
    "      }\n",
    "    })\n",
    "    \n",
    "    if (!inherits(result, \"error\")) {\n",
    "      message(sprintf(\"日期 %s 数据提取成功。\", date_char))\n",
    "      break\n",
    "    }\n",
    "    # 若发生错误，则继续重试\n",
    "  }\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 定义日期范围（示例：2023 年 1 月每日数据）\n",
    "# -----------------------------\n",
    "start_date <- as.Date(\"2023-01-01\")\n",
    "end_date   <- as.Date(\"2023-01-31\")\n",
    "dates <- seq.Date(start_date, end_date, by = \"day\")\n",
    "date_chars <- as.character(dates)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 使用 future.apply 的 future_lapply 进行多线程并行提取\n",
    "# -----------------------------\n",
    "plan(multisession)  # 设置并行计划，支持跨平台\n",
    "\n",
    "future_lapply(date_chars, function(d) {\n",
    "  bm_extract_day(date_char = d, roi_sf = local_area_sf, bearer = bearer, wait_seconds = 10)\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# 6. 合并所有生成的 .Rds 文件，并导出为 CSV 文件\n",
    "# -----------------------------\n",
    "all_rds_daily <- list.files(\"bm_files_daily\", pattern = \"\\\\.Rds$\", recursive = TRUE, full.names = TRUE)\n",
    "daily_data <- purrr::map_df(all_rds_daily, readRDS)\n",
    "\n",
    "# 查看合并数据的前几行\n",
    "print(head(daily_data))\n",
    "\n",
    "# 将合并后的数据导出为 CSV 文件\n",
    "write.csv(daily_data, \"daily_ntl_data.csv\", row.names = FALSE)\n",
    "message(\"所有日数据已合并，并保存为 daily_ntl_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
